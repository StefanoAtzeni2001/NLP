## Word Sense Disambiguation (WSD)
This is a university project created for the NLP course.\
The aim is to implement and test word sense disambiguation (WSD) algorithms.

The following code implements the **Lesk** algorithm and some variants to perform WSD on sentences extracted from the **SemCor** dataset, which consists of text annotated with the synsets of **WordNet**.\
The main objective is to determine the meaning of a word within a given context; in this process, the use of WordNet plays a crucial role.\
Each word is associated with one or more synsets that represent its different meanings, sometimes very subtle. Consequently, disambiguation involves associating the word with the corresponding synset.

The Lesk algorithm is based on the premise that the meaning of a word is determined by the context in which it is used, namely the words that appear around it.\
The basic idea is to obtain the **context** of the word to be disambiguated and compare it with the **signatures** of each synset for that term, trying to find the one with the maximum overlap.

### Implemented Algorithms
A Naive approach and 3 variants of the Lesk algorithm have been implemented:
- **Naive**\
Disambiguation is performed by assigning the most frequent synset of the word.\
This is a trivial implementation since WordNet provides synsets in order of frequency.

- **Lesk (base)**\
The signature is given by the definition (gloss) and examples of the synset present on WordNet.\
The overlap is calculated as the number of common words between the context and the signature. Stopwords are removed as they are not significant.

- **Corpus Lesk with SemCor**\
The signature of each synset is extended by adding all sentences from SemCor in which it appears.\
Considering a larger amount of data, it is necessary to assign weights to the words so that they reflect their importance.\
The weights are calculated with Inverse Document Frequency **(IDF)**, which measures in how many "documents" (sentences) a word appears.\
In this way, all words are retained, including stopwords, but those that are too common will have a lower weight.\
$idf_i = \log\frac{Ndoc}{Nd_i}$ where $Ndoc$ is the total number of sentences and $N_{d_i}$ is the number of sentences in which word $i$ appears.\
The overlap is calculated as the sum of the weights of the words common between the context and the signature.

- **Corpus Lesk with SemCor + Examples generated by Gemini**\
The signatures are further extended by adding sentences generated by **Gemini**, in an attempt to further refine the signatures.\
The implementation of overlap and weights is identical to the previous one.\
To obtain satisfactory results from Gemini, the **COSTAR** framework was used for **prompt engineering**.

### Results
Testing (multiple times) the algorithms on 50 sentences for 10 times, we obtain the following average accuracy:
- Naive: 35-40%
- Lesk: 45-60%
- Corpus Lesk: **75-80%**
- Corpus Lesk Gemini: 70-80%

As expected, the base Lesk algorithm has a higher accuracy than the Naive approach, but a more extended signature like that of Corpus Lesk allows for better results.\
However, further refinement with examples from Gemini does not lead to a significant improvement. Evidently, despite the generated examples being coherent, they are not always useful for disambiguation, in fact when only Gemini examples are used the performance drops significally.\
If the problem is restricted to disambiguating only Nouns, the Naive algorithm achieves significantly better performance, sometimes surpassing the base Lesk, while Corpus Lesk further increases its accuracy.

Note: Corpus Lesk Gemini was tested on smaller samples as it is much slower due to api calls limits.
